{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "- get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from process_data import *\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigcomp\n",
      "load data : ../data/target/fold_1/train.pkl\n",
      "5206 5206\n",
      "load data : ../data/target/fold_1/dev.pkl\n",
      "729 729\n",
      "load data : ../data/target/fold_1/test.pkl\n",
      "1445 1445\n",
      "[completed] load data\n"
     ]
    }
   ],
   "source": [
    "params = Params()\n",
    "params.data_path = '../data/target/fold_1/'\n",
    "graph_name = 'bigcomp'\n",
    "batch_gen = ProcessData(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1582) (10, 6)\n"
     ]
    }
   ],
   "source": [
    "list_d, list_l = batch_gen.get_batch(\n",
    "                            data=batch_gen.test,\n",
    "                            batch_size=10,\n",
    "                            is_test=False,\n",
    "                            start_index = 0\n",
    "                            )\n",
    "print(np.shape(list_d), np.shape(list_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigcomp\n",
      "load data : ../data/target/fold_1/train.pkl\n",
      "5206 5206\n",
      "load data : ../data/target/fold_1/dev.pkl\n",
      "729 729\n",
      "load data : ../data/target/fold_1/test.pkl\n",
      "1445 1445\n",
      "[completed] load data\n",
      "[launch] placeholders\n",
      "[INFO] MLP\n",
      "[launch] MLP (reuse, scope):  False L1\n",
      "[launch] MLP (reuse, scope):  False L2\n",
      "[launch] create output projection layer\n",
      "[launch] create optimizer\n",
      "[launch] create summary\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from model import *\n",
    "from process_data import *\n",
    "from params import *\n",
    "# from train import *\n",
    "\n",
    "params = Params()\n",
    "params.DATA_PATH = '../data/target/fold_1/'\n",
    "graph_name = 'bigcomp'\n",
    "##########################################    \n",
    "params.IS_RESULT_LOGGIN = False\n",
    "##########################################          \n",
    "batch_gen = ProcessData(params)\n",
    "\n",
    "params.BATCH_SIZE = 2\n",
    "params.LR = 1e-3\n",
    "params.NUM_LAYERS = 2\n",
    "\n",
    "model = SimpleMLP(params=params)\n",
    "\n",
    "model.build_graph()\n",
    "# model._create_placeholders()\n",
    "# model._apply_MLP()\n",
    "# model._create_output_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'L1/L1mlp/weights:0' shape=(1582, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'L1/L1mlp/biases:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'L2/L2mlp/weights:0' shape=(100, 100) dtype=float32_ref>,\n",
       " <tf.Variable 'L2/L2mlp/biases:0' shape=(100,) dtype=float32_ref>,\n",
       " <tf.Variable 'text_output_layer/W_output:0' shape=(100, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'text_output_layer/bias_output:0' shape=(6,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver  = tf.train.Saver()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# if exists check point, starts from the check point\n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('./save/'))\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    print ('from check point!!!')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_d, list_l = batch_gen.get_batch(\n",
    "                                    data=batch_gen.dev,\n",
    "                                    batch_size=model.params.BATCH_SIZE,\n",
    "                                    is_test=True,\n",
    "                                    start_index = 0\n",
    "                                    )\n",
    "\n",
    "# prepare data which will be push from pc to placeholder\n",
    "input_feed = {}\n",
    "\n",
    "input_feed[model.batch_d]     = list_d\n",
    "input_feed[model.batch_l]     = list_l\n",
    "input_feed[model.dr_prob] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() (2,) ()\n"
     ]
    }
   ],
   "source": [
    "r1, r2, r3 = sess.run( [\n",
    "                model.lossL2,\n",
    "                model.batch_loss,\n",
    "                model.loss\n",
    "               ], input_feed)\n",
    "\n",
    "print(np.shape(r1), np.shape(r2), np.shape(r3))\n",
    "# print(list_len_q)\n",
    "# print(list_len_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028755648"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6433585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load glove] W_embedding.npy\n",
      "[completed] loading pre-trained embedding vector to placeholder\n",
      "[completed] loading pre-trained embedding vector to placeholder\n",
      "[completed] loading pre-trained embedding vector to placeholder\n",
      "0 mins step/seen/itr: 2/ 2000/0.18\tdev: 1.000 1.000  test: 1.000 1.000  train: 0.000  loss: 0.0000\n",
      "best result (MAP/MRR) \n",
      "dev   : 1.000\t1.000\n",
      "test  : 1.000\t1.000\n",
      "train : 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(params, model, batch_gen, num_train_steps=2, valid_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigcomp\n",
      "load data : ../data/target/fold_1/train.pkl\n",
      "5206 5206\n",
      "load data : ../data/target/fold_1/dev.pkl\n",
      "729 729\n",
      "load data : ../data/target/fold_1/test.pkl\n",
      "1445 1445\n",
      "[completed] load data\n",
      "[launch] placeholders\n",
      "[INFO] MLP\n",
      "[launch] MLP (reuse, scope):  False L1\n",
      "[launch] create output projection layer\n",
      "[launch] create optimizer\n",
      "[launch] create summary\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from model import *\n",
    "from process_data import *\n",
    "from params import *\n",
    "from evaluation import *\n",
    "# from train import *\n",
    "\n",
    "params = Params()\n",
    "params.data_path = '../data/target/fold_1/'\n",
    "graph_name = 'bigcomp'\n",
    "##########################################    \n",
    "params.IS_RESULT_LOGGIN = False\n",
    "##########################################          \n",
    "batch_gen = ProcessData(params)\n",
    "\n",
    "params.batch_size = 2\n",
    "params.lr = 1e-3\n",
    "\n",
    "model = SimpleMLP(params=params)\n",
    "\n",
    "model.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pre-model available\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# if exists check point, starts from the check point\n",
    "ckpt = tf.train.get_checkpoint_state(os.path.dirname('./save/best-model/'))\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    print ('from check point!!!')\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"no pre-model available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12488455453227748 0.1083170493404983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dato/anaconda2/envs/tf14_p35/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "data         = batch_gen.dev\n",
    "test_loss, test_MAP, test_MRR, _ = run_test(sess=sess,\n",
    "                                     model=model,\n",
    "                                     batch_gen=batch_gen,\n",
    "                                     data=data\n",
    "                                           )\n",
    "print(test_MAP, test_MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_d, list_l = batch_gen.get_batch(\n",
    "                                    data=batch_gen.dev,\n",
    "                                    batch_size=2,\n",
    "                                    is_test=True,\n",
    "                                    start_index = 0\n",
    "                                    )\n",
    "\n",
    "# prepare data which will be push from pc to placeholder\n",
    "input_feed = {}\n",
    "\n",
    "input_feed[model.batch_d] = list_d\n",
    "input_feed[model.batch_l] = list_l\n",
    "input_feed[model.dr_prob] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6) (2, 6) ()\n"
     ]
    }
   ],
   "source": [
    "r1, r2, r3 = sess.run( [\n",
    "                model.batch_preds,\n",
    "                model.y_labels,\n",
    "                model.loss\n",
    "               ], input_feed)\n",
    "\n",
    "print(np.shape(r1), np.shape(r2), np.shape(r3))\n",
    "# print(list_len_q)\n",
    "# print(list_len_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49230745, 0.49239844, 0.4924431 , 0.5004191 , 0.5028848 ,\n",
       "       0.5003315 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(r2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf14_p35]",
   "language": "python",
   "name": "conda-env-tf14_p35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
